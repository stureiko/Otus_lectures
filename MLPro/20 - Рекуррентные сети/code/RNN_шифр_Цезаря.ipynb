{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc-yAxE4AREK",
        "outputId": "af24fc56-9558-4310-db61-6c3d82ab6dcf"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OanDZadVASzf"
      },
      "source": [
        "https://calvinfeng.gitbook.io/machine-learning-notebook/supervised-learning/recurrent-neural-network/long_short_term_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rw3r34h6AcpO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# import nltk\n",
        "import gensim.downloader as api\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2rVMODMAhtm"
      },
      "outputs": [],
      "source": [
        "# Зафиксируем seed для воспроизводимости\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed) # Фиксируем генератор случайных чисел\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed) # Фиксируем заполнения хешей\n",
        "    np.random.seed(seed) # Фиксируем генератор случайных чисел numpy\n",
        "    torch.manual_seed(seed) # Фиксируем генератор случайных чисел pytorch\n",
        "    torch.cuda.manual_seed(seed) # Фиксируем генератор случайных чисел для GPU\n",
        "    torch.backends.cudnn.deterministic = True # Выбираем только детерминированные алгоритмы (для сверток)\n",
        "    torch.backends.cudnn.benchmark = False # Фиксируем алгоритм вычисления сверток"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaMz4w4OAnE_"
      },
      "outputs": [],
      "source": [
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XlmRXlGC3PP"
      },
      "source": [
        "# Дешифрация текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcXwbDlwC3X3"
      },
      "source": [
        "Представьте, что вам даны сообщения зашифрованные с помощью шифра Цезаря, являющимся одним из самых простых шифров в криптографии.\n",
        "\n",
        "Шифр Цезаря работает следующим образом: каждая буква исходного алфавита сдвигается на K символов вправо.\n",
        "\n",
        "Пусть нам дано сообщение: message=\"RNN IS NOT AI\", тогда наше шифрование выполняющиеся по правилу f, с K=2, даст нам результат:\n",
        "f(message, K) = TPPAKUAPQVACK\n",
        "\n",
        "Для удобства можно взять символы только одного регистра в нашей имплементации, и сказать, что все буквы НЕ ОТНОСЯЩИЕСЯ к английскому алфавиту будут отмечены как прочерк \"-\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uBSJhSYC8nX"
      },
      "outputs": [],
      "source": [
        "# Определим ключ и словарь\n",
        "key = 2\n",
        "vocab = [char for char in ' -ABCDEFGHIJKLMNOPQRSTUVWXYZ!?']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haGFsU5-DXNL",
        "outputId": "305670bc-7da0-4c93-e4e0-a5f5cdb17275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TPPAKUAPQVACK\n"
          ]
        }
      ],
      "source": [
        "# Напишем функцию, которая делает шифр\n",
        "def encrypt(text, key):\n",
        "    \"\"\"\"Возвращает зашифрованную форму 'text'.\"\"\"\n",
        "    indexes = [vocab.index(char) for char in text] # для каджого символя из 'text' получаем индекс из словаря\n",
        "    encrypted_indexes = [(idx + key) % len(vocab) for idx in indexes] # каждому индексу мы получаем новый зашифрованный индекс\n",
        "    # print(indexes)\n",
        "    # print(encrypted_indexes)\n",
        "    encrypted_chars = [vocab[idx] for idx in encrypted_indexes] # получаем новую фразу\n",
        "    encrypted = ''.join(encrypted_chars)\n",
        "    return encrypted\n",
        "\n",
        "print(encrypt('RNN IS NOT AI', key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ6RzQqFLU6T"
      },
      "outputs": [],
      "source": [
        "num_examples = 256 # размер датасета\n",
        "seq_len = 18 # максимальная длина строки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au89RJwAKtl4"
      },
      "outputs": [],
      "source": [
        "def encrypted_dataset(dataset_len, k):\n",
        "    \"\"\"\n",
        "    Return: List(Tuple(Tensor encrypted, Tensor source))\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    for x in range(dataset_len):\n",
        "        random_message  = ''.join([random.choice(vocab) for x in range(seq_len)])\n",
        "        encrypt_random_message = encrypt(''.join(random_message), k)\n",
        "        src = [vocab.index(x) for x in random_message]\n",
        "        tgt = [vocab.index(x) for x in encrypt_random_message]\n",
        "        dataset.append([torch.tensor(tgt), torch.tensor(src)])\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrkaHI0zK2bw"
      },
      "outputs": [],
      "source": [
        "class Decipher(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim,\n",
        "                rnn_type='simple'):\n",
        "        \"\"\"\n",
        "        :params: int vocab_size\n",
        "        :params: int embedding_dim\n",
        "        :params\n",
        "        \"\"\"\n",
        "        super(Decipher, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if rnn_type == 'simple':\n",
        "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers = 2)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.initial_hidden = torch.zeros(2, 1, hidden_dim)\n",
        "\n",
        "\n",
        "    def forward(self, cipher):\n",
        "        # CHECK INPUT SIZE\n",
        "        # Unsqueeze 1 dimension for batches\n",
        "        embd_x = self.embed(cipher).unsqueeze(1)\n",
        "        out_rnn, hidden = self.rnn(embd_x, self.initial_hidden)\n",
        "        # Apply the affine transform and transpose output in appropriate way\n",
        "        # because you want to get the softmax on vocabulary dimension\n",
        "        # in order to get probability of every letter\n",
        "        return self.fc(out_rnn).transpose(1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMw1h1BYK53H"
      },
      "outputs": [],
      "source": [
        "# Определим параметры нашей модели\n",
        "embedding_dim = 5\n",
        "hidden_dim = 10\n",
        "vocab_size = len(vocab)\n",
        "lr = 1e-3\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Инициализируйте модель\n",
        "model = Decipher(vocab_size, embedding_dim, hidden_dim)\n",
        "\n",
        "# Инициализируйте оптимизатор: рекомендуется Adam\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX0_ZK-TK-xw",
        "outputId": "d6290e76-38cd-46c4-a6dd-a1501afec512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  0, Loss: 2.7445,  Accuracy: 31.34%\n",
            "Epoch:  1, Loss: 1.8754,  Accuracy: 70.90%\n",
            "Epoch:  2, Loss: 1.2083,  Accuracy: 90.17%\n",
            "Epoch:  3, Loss: 0.8470,  Accuracy: 97.24%\n",
            "Epoch:  4, Loss: 0.6072,  Accuracy: 99.93%\n",
            "Epoch:  5, Loss: 0.4411,  Accuracy: 100.00%\n",
            "Epoch:  6, Loss: 0.3088,  Accuracy: 100.00%\n",
            "Epoch:  7, Loss: 0.3093,  Accuracy: 100.00%\n",
            "Epoch:  8, Loss: 0.2334,  Accuracy: 100.00%\n",
            "Epoch:  9, Loss: 0.1643,  Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "k = 10 # смещение\n",
        "for x in range(num_epochs):\n",
        "    print('Epoch: {:2.0f}'.format(x), end=', ')\n",
        "    for encrypted, original in encrypted_dataset(num_examples, k):\n",
        "\n",
        "        scores = model(encrypted)\n",
        "        original = original.unsqueeze(1)\n",
        "        # Calculate loss\n",
        "        loss = criterion(scores, original)\n",
        "        # Zero grads\n",
        "        optimizer.zero_grad()\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "    print('Loss: {:6.4f}'.format(loss.item()), end=',  ')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        matches, total = 0, 0\n",
        "        for encrypted, original in encrypted_dataset(num_examples, k):\n",
        "            # Compute a softmax over the outputs\n",
        "            predictions = F.softmax(model(encrypted), 1)\n",
        "            # Choose the character with the maximum probability (greedy decoding)\n",
        "            _, batch_out = predictions.max(dim=1)\n",
        "            # Remove batch\n",
        "            batch_out = batch_out.squeeze(1)\n",
        "            # Calculate accuracy\n",
        "            matches += torch.eq(batch_out, original).sum().item()\n",
        "            total += torch.numel(batch_out)\n",
        "        accuracy = matches / total\n",
        "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_b_m0mKLd-h",
        "outputId": "216143ae-863f-4cad-a174-e72f8c810d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source: HELLO WORLD\n",
            "Encrypted: tensor([ 7,  9, 13,  6,  6,  1, 20, 29, 12, 12, 25, 20,  0, 16, 17, 13, 24, 11])\n",
            "Predictions: HELLO WORLD\n"
          ]
        }
      ],
      "source": [
        "source = 'HELLO WORLD'\n",
        "# coding\n",
        "tgt = [vocab.index(x) for x in encrypt(''.join(source), k)]\n",
        "# decoding\n",
        "_, batch_out = F.softmax(model(torch.tensor(tgt)), 1).max(dim=1)\n",
        "\n",
        "print(f'Source: {source}')\n",
        "print(f'Encrypted: {encrypted}')\n",
        "print(f'Predictions: {\"\".join([vocab[i] for i in batch_out])}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
