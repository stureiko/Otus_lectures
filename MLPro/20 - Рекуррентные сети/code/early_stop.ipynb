{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим ключ и словарь\n",
    "key = 2\n",
    "vocab = [char for char in ' -ABCDEFGHIJKLMNOPQRSTUVWXYZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPPAKUAPQVACK\n"
     ]
    }
   ],
   "source": [
    "# Напишем функцию, которая делает шифр\n",
    "def encrypt(text, key):\n",
    "    \"\"\"Returns the encrypted form of 'text'.\"\"\"\n",
    "    indexes = [vocab.index(char) for char in text]\n",
    "    encrypted_indexes = [(idx + key) % len(vocab) for idx in indexes]\n",
    "    encrypted_chars = [vocab[idx] for idx in encrypted_indexes]\n",
    "    encrypted = ''.join(encrypted_chars)\n",
    "    return encrypted\n",
    "\n",
    "print(encrypt('RNN IS NOT AI', key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 256 # размер датасета\n",
    "seq_len = 18 # максимальная длина строки\n",
    "\n",
    "\n",
    "def encrypted_dataset(dataset_len, k):\n",
    "    \"\"\"\n",
    "    Return: List(Tuple(Tensor encrypted, Tensor source))\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for x in range(dataset_len):\n",
    "        random_message  = ''.join([random.choice(vocab) for x in range(seq_len)])\n",
    "        encrypt_random_message = encrypt(''.join(random_message), k)\n",
    "        src = [vocab.index(x) for x in random_message]\n",
    "        tgt = [vocab.index(x) for x in encrypt_random_message]\n",
    "        dataset.append([torch.tensor(tgt), torch.tensor(src)])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decipher(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \n",
    "                rnn_type='simple'):\n",
    "        \"\"\"\n",
    "        :params: int vocab_size \n",
    "        :params: int embedding_dim\n",
    "        :params\n",
    "        \"\"\"\n",
    "        super(Decipher, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if rnn_type == 'simple':\n",
    "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers = 2)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.initial_hidden = torch.zeros(2, 1, hidden_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, cipher):\n",
    "        # CHECK INPUT SIZE\n",
    "        # Unsqueeze 1 dimension for batches\n",
    "        embd_x = self.embed(cipher).unsqueeze(1)\n",
    "        out_rnn, hidden = self.rnn(embd_x, self.initial_hidden)\n",
    "        # Apply the affine transform and transpose output in appropriate way\n",
    "        # because you want to get the softmax on vocabulary dimension\n",
    "        # in order to get probability of every letter\n",
    "        return self.fc(out_rnn).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим параметры нашей модели\n",
    "embedding_dim = 5\n",
    "hidden_dim = 10\n",
    "vocab_size = len(vocab) \n",
    "lr = 1e-3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Инициализируйте модель\n",
    "model = Decipher(vocab_size, embedding_dim, hidden_dim)\n",
    "\n",
    "# Инициализируйте оптимизатор: рекомендуется Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация ранней остановки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0, Loss: 2.6906,  Accuracy: 34.09%\n",
      "Epoch:  1, Loss: 1.7214,  Accuracy: 77.78%\n",
      "Epoch:  2, Loss: 1.1368,  Accuracy: 87.02%\n",
      "Epoch:  3, Loss: 0.7830,  Accuracy: 97.22%\n",
      "Epoch:  4, Loss: 0.5837,  Accuracy: 100.00%\n",
      "Epoch:  5, Loss: 0.3572,  Accuracy: 100.00%\n",
      "Epoch:  6, Loss: 0.2724,  Accuracy: 100.00%\n",
      "Epoch:  7, Loss: 0.2102,  Accuracy: 100.00%\n",
      "Epoch:  8, Loss: 0.1548,  Accuracy: 100.00%\n",
      "Epoch:  9, Loss: 0.1329,  Accuracy: 100.00%\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "# Инициализация переменных для ранней остановки\n",
    "best_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "n_epochs_stop = 5\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "for x in range(num_epochs):\n",
    "    print('Epoch: {:2.0f}'.format(x), end=', ')\n",
    "    for encrypted, original in encrypted_dataset(num_examples, k):\n",
    "\n",
    "        scores = model(encrypted)\n",
    "        original = original.unsqueeze(1)\n",
    "        # Calculate loss\n",
    "        loss = criterion(scores, original)\n",
    "        # Zero grads\n",
    "        optimizer.zero_grad()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    print('Loss: {:6.4f}'.format(loss.item()), end=',  ')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        matches, total = 0, 0\n",
    "        for encrypted, original in encrypted_dataset(num_examples, k):\n",
    "            # Compute a softmax over the outputs\n",
    "            predictions = F.softmax(model(encrypted), 1)\n",
    "            # Choose the character with the maximum probability (greedy decoding)\n",
    "            _, batch_out = predictions.max(dim=1)\n",
    "            # Remove batch\n",
    "            batch_out = batch_out.squeeze(1)\n",
    "            # Calculate accuracy\n",
    "            matches += torch.eq(batch_out, original).sum().item()\n",
    "            total += torch.numel(batch_out)\n",
    "        accuracy = matches / total\n",
    "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))\n",
    "        \n",
    "        # Обработка ранней остановки\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "    \n",
    "        # Остановка, если качество не улучшается\n",
    "        if epochs_no_improve == n_epochs_stop:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавим логирование результатов в Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Импортировать TensorBoard: Для начала необходимо импортировать необходимый класс SummaryWriter из torch.utils.tensorboard.\n",
    "2. Создать экземпляр SummaryWriter: Это будет использоваться для записи данных.\n",
    "3. Логировать данные: Вы можете логировать различные метрики (например, потери и точность) во время обучения и проверки модели.\n",
    "4. Запустить TensorBoard: После запуска скрипта, TensorBoard можно запустить локально для просмотра результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0, Loss: 2.6422,  Accuracy: 32.92%\n",
      "Epoch:  1, Loss: 1.8693,  Accuracy: 66.97%\n",
      "Epoch:  2, Loss: 1.2075,  Accuracy: 84.96%\n",
      "Epoch:  3, Loss: 0.8928,  Accuracy: 98.46%\n",
      "Epoch:  4, Loss: 0.6485,  Accuracy: 100.00%\n",
      "Epoch:  5, Loss: 0.4252,  Accuracy: 100.00%\n",
      "Epoch:  6, Loss: 0.3391,  Accuracy: 100.00%\n",
      "Epoch:  7, Loss: 0.3324,  Accuracy: 100.00%\n",
      "Epoch:  8, Loss: 0.2439,  Accuracy: 100.00%\n",
      "Epoch:  9, Loss: 0.1465,  Accuracy: 100.00%\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "# Инициализация переменных для ранней остановки\n",
    "best_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "n_epochs_stop = 5\n",
    "num_epochs = 20\n",
    "\n",
    "# Создаем экземпляр для TensorBoard\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for x in range(num_epochs):\n",
    "    print('Epoch: {:2.0f}'.format(x), end=', ')\n",
    "    for encrypted, original in encrypted_dataset(num_examples, k):\n",
    "\n",
    "        scores = model(encrypted)\n",
    "        original = original.unsqueeze(1)\n",
    "        # Calculate loss\n",
    "        loss = criterion(scores, original)\n",
    "        # Zero grads\n",
    "        optimizer.zero_grad()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    print('Loss: {:6.4f}'.format(loss.item()), end=',  ')\n",
    "    \n",
    "    # Логирование потерь в TensorBoard\n",
    "    writer.add_scalar('Loss/train', loss.item(), x)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        matches, total = 0, 0\n",
    "        for encrypted, original in encrypted_dataset(num_examples, k):\n",
    "            # Compute a softmax over the outputs\n",
    "            predictions = F.softmax(model(encrypted), 1)\n",
    "            # Choose the character with the maximum probability (greedy decoding)\n",
    "            _, batch_out = predictions.max(dim=1)\n",
    "            # Remove batch\n",
    "            batch_out = batch_out.squeeze(1)\n",
    "            # Calculate accuracy\n",
    "            matches += torch.eq(batch_out, original).sum().item()\n",
    "            total += torch.numel(batch_out)\n",
    "        accuracy = matches / total\n",
    "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))\n",
    "        \n",
    "        # Логирование точности в TensorBoard\n",
    "        writer.add_scalar('Accuracy/train', accuracy, x)\n",
    "\n",
    "        # Обработка ранней остановки\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "    \n",
    "        # Остановка, если качество не улучшается\n",
    "        if epochs_no_improve == n_epochs_stop:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.15.1 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# !tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
