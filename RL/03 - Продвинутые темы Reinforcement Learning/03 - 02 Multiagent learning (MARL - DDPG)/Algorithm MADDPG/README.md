# Описание

Алгоритм мультиагентного глубокого детерминированного градиента стратегий (англ. Multiagent Deep Deterministic Policy Gradient, MADDPG) представляет собой расширение алгоритма DDPG для мультиагентного случая.
Алгоритм MADDPG создавался командой OpenAI, с целью преодоления проблем координации, нестационарности и нестабильности мультиагентного обучения.  

Основной программной библиотекой, используемой в данном примере, является библиотека кооперативного мультиагентного обучения SMAC (англ. StarCraft Multi-Agent Challenge). Кроме того, используются прикладной программный интерфейс машинного обучения StarCraft II от компании Blizzard и программная библиотека РySC2 , разработанная компанией DeepMind.

Для запуска примеров обучения необходимо также установить бесплатный клиент компьютерной стратегической игры StarCraft II через приложение цифровой дистрибуции Blizzard Battle.net.

## Новая карта

Карта 3ps1zgWallFOX.SC2Map создана на базе карты SMAC в редакторе карт StarCraft II Editor.
Для подключения карты необходимо добавить в файл smac_maps.py, расположенный в папке `...\smac\env\starcraft2\maps` следующую структуру:
`"3ps1zgWallFOX": {
        "n_agents": 3,
        "n_enemies": 1,
        "limit": 240,
        "a_race": "P",
        "b_race": "Z",
        "unit_type_bits": 0,
        "map_type": "stalkers",
    },`

Кроме того, файл с новой картой *.SC2Map должен быть добавлен впапку «..\StarCraft II\Maps\SMAC_Maps».

При обучении удобно ускорять визуализацию игры, а при анализе результатов нужен реальный масштаб времени. Существует возможность настройки скорости визуализации StarCraft II изменением значения переменной realtime c True на False в файле starcraft2.ру, находящемся в папке «...\smac\env\starcraft2». После модификации настроек скорости или добавления новой карты необходимо перезапустить среду разработки, чтобы загрузилась библиотека с изменениями.
