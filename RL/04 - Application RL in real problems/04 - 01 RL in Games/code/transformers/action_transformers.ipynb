{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use action_transformer environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<https://medium.com/@kaige.yang0110/ray-rllib-how-to-train-dreamerv3-on-vizdoom-and-atari-122c8bd1170b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import vizdoom as vzd\n",
    "import skimage.transform\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ENV = \"VizdoomBasic-v0\"\n",
    "AVAILABLE_ENVS = [\n",
    "    env\n",
    "    for env in [env_spec.id for key, env_spec in gym.envs.registry.items()]\n",
    "    if \"Vizdoom\" in env\n",
    "]\n",
    "# Height and width of the resized image\n",
    "IMAGE_SHAPE = (64, 64)\n",
    "\n",
    "# Training parameters\n",
    "TRAINING_TIMESTEPS = int(1e6)\n",
    "N_STEPS = 128\n",
    "N_ENVS = 8\n",
    "FRAME_SKIP = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservationWrapper(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    ViZDoom environments return dictionaries as observations, containing\n",
    "    the main image as well other info.\n",
    "    The image is also too large for normal training.\n",
    "\n",
    "    This wrapper replaces the dictionary observation space with a simple\n",
    "    Box space (i.e., only the RGB image), and also resizes the image to a\n",
    "    smaller size.\n",
    "\n",
    "    NOTE: Ideally, you should set the image size to smaller in the scenario files\n",
    "        for faster running of ViZDoom. This can really impact performance,\n",
    "        and this code is pretty slow because of this!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, shape=IMAGE_SHAPE):\n",
    "        super().__init__(env)\n",
    "        self.image_shape = shape\n",
    "        # print('shape', shape)\n",
    "        self.image_shape_reverse = shape[::-1]\n",
    "        # print('image_shape_reverse', self.image_shape_reverse)\n",
    "        self.env.frame_skip = FRAME_SKIP\n",
    "\n",
    "        # Create new observation space with the new shape\n",
    "        # print('env.obs', env.observation_space)\n",
    "        num_channels = env.observation_space[\"screen\"].shape[-1]\n",
    "        new_shape = (self.image_shape[0], self.image_shape[1], num_channels)\n",
    "        # print('new_shape', new_shape)\n",
    "        self.observation_space = gym.spaces.Box(0, 255, shape=new_shape, dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # print('observation[\"screen\"].shape', observation[\"screen\"].shape)\n",
    "        observation = cv2.resize(observation[\"screen\"], self.image_shape_reverse)\n",
    "        # print('obs.shape', observation.shape)\n",
    "        observation = observation.astype('float32')\n",
    "        # print('obs.shape', observation.shape)\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_env(env):\n",
    "    env = ObservationWrapper(env)\n",
    "    env = gym.wrappers.TransformReward(env, lambda r: r * 0.01)\n",
    "    return env\n",
    "\n",
    "def reward_wrap_env(env):\n",
    "    env = gym.wrappers.TransformReward(env, lambda r: r * 0.01)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vizdoom.gymnasium_wrapper  # noqa\n",
    "import vizdoom\n",
    "from vizdoom.gymnasium_wrapper.gymnasium_env_defns import VizdoomScenarioEnv\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"scenario_file\": \"basic.cfg\"}\n",
    "def env_creator(env_config):\n",
    "    return wrap_env(VizdoomScenarioEnv(**config))\n",
    "register_env('vizdoom_env', env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.rllib.algorithms.dreamerv3.dreamerv3 import DreamerV3Config\n",
    "\n",
    "ray.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = int(ray.cluster_resources()['CPU'])\n",
    "# num_gpus = int(ray.cluster_resources()['GPU'])\n",
    "\n",
    "num_learner_workers = num_cpus-1\n",
    "# num_gpus_per_learner_worker = 1\n",
    "num_cpus_per_learner_workers = 1\n",
    "\n",
    "config = (\n",
    "        DreamerV3Config()\n",
    "        .environment(\n",
    "            env='vizdoom_env',\n",
    "        )\n",
    "        .learners(\n",
    "            # num_learner=num_learner_workers,\n",
    "            num_cpus_per_learner=num_cpus_per_learner_workers,\n",
    "        )\n",
    "        .resources(\n",
    "            num_learner_workers=num_learner_workers,\n",
    "            # num_gpus_per_learner_worker=1,\n",
    "            # num_cpus_for_local_worker=1,\n",
    "            num_cpus_for_main_process = 1,\n",
    "            # num_cpus_per_learner_worker=num_cpus_per_learner_workers,\n",
    "        )\n",
    "        .rollouts(num_envs_per_env_runner=1, remote_worker_envs=False)\n",
    "        .training(\n",
    "            model_size=\"S\",\n",
    "            training_ratio=512,\n",
    "            batch_size_B=16*num_learner_workers,\n",
    "        )\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_num = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = config.build()\n",
    "print('------ algo=', algo)\n",
    "for iteration in tqdm(range(iteration_num)):\n",
    "    result = algo.train()\n",
    "    print('result.keys', result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train, tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_save_freq = 100\n",
    "tuner = tune.Tuner(\n",
    "    \"DreamerV3\",\n",
    "    run_config=train.RunConfig(\n",
    "        stop={\"training_iteration\": iteration_num},\n",
    "        checkpoint_config=train.CheckpointConfig(checkpoint_frequency=ck_save_freq, checkpoint_at_end=True)\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "result = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
